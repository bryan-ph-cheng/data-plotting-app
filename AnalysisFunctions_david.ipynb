{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Initialization and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import tools\n",
    "import plotly.io as pio\n",
    "import qcodes as qc\n",
    "import numpy as np\n",
    "from plotly import graph_objs as go\n",
    "from qcodes.instrument_drivers.rohde_schwarz import SGS100A\n",
    "from time import sleep\n",
    "from qcodes.dataset.measurements import Measurement\n",
    "import qcodes.dataset.experiment_container as exc\n",
    "from scipy.optimize import curve_fit\n",
    "import datetime\n",
    "import scipy.fftpack\n",
    "from scipy import signal\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config file from //anaconda3/lib/python3.7/site-packages/qcodes/config/qcodesrc.json\n",
      "Database location: ./2019-07-08-frays-final.db\n"
     ]
    }
   ],
   "source": [
    "configuration = qc.config\n",
    "print(f'Using config file from {configuration.current_config_path}')\n",
    "configuration['core']['db_location'] = './2019-07-08-frays-final.db'\n",
    "print(f'Database location: {configuration[\"core\"][\"db_location\"]}')\n",
    "qc.initialise_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['magFieldAlignment', 'ODMR_check', 'Alignement_Improvement', 'Calibration', 'overnight_Rabi', 'power_check_rabi', 'frequency_checks', 'overnight_peakonly_spinecho', 'overnight_peakonly_spinecho_for_real', 'pulsedOdmr_central_7', 'pulsedOdmr_rabi_central_7', 'pulsedOdmr_rabi_echo_weekend_7', 'pulsedOdmr_rabi_echo_postCooldown_70K', 'pulsedOdmr_rabi_echo_postCooldown_70K_forReal', 'pulsedOdmr_rabi_echo_postCooldown_70K_adjustedFreq', 'pulsedOdmr_rabi_echo_postCooldown_70K_Overnight', 'pulsedOdmr_rabi_echo_40K_Overnight', 'pulsedOdmr_rabi_echo_40K_check', 'rabi_echo_40K', 'cwODMR_15K', 'pulsedOdmr_rabi_echo_15K', 'pulsedOdmr_rabi_echo_15K_overnight', 'pulsedOdmr_rabi_echo_15K_final', 'pulsedOdmr_rabi_echo_2-5K', 'pulsedOdmr_rabi_echo_2K', 'pulsedOdmr_7NVs_2K', 'Odmr_7NVs_100K', 'pulsedOdmr_7NVs_100K', 'pulsedOdmr_rabi_spinecho_7NVs_100K', 'pulsedOdmr_rabi_spinecho_7NVs_100K_overnight', 'pulsedOdmr_rabi_spinecho_7NVs_40K', 'CWodmr_7NVs_40K', 'rabi_spinEcho_7NVs_40K', 'cwODMR_7NVs_55K', 'rabi_spinEcho_7NVs_55K', 'cwODMR_7NVs_25K', 'rabi_spinEcho_7NVs_25K', 'nmr_tests_7NVs_25K', 'nmr_tests_7NVs_15K', 'nmr_NV1_15K', 'pulsedODMR_NV1_15K', 'xySequenceTests_NV1_15K', 'xy32_NV1_15K_overnight', 'pulsedODMR_7NVs_7K', '100K_check', '100K_highMagField', '100K_cpmg', '100K_xy8']\n"
     ]
    }
   ],
   "source": [
    "experimentsList = [exp.name for exp in exc.experiments()]\n",
    "print(experimentsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeCounts(countArray, num):\n",
    "    reb_counts = np.squeeze(countArray)/np.mean(np.sort(np.squeeze(countArray))[-num:])\n",
    "    return reb_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorentzian(x, x0, a0, g, amp):\n",
    "    denom = (x - x0)**2 + (0.5*g)**2\n",
    "    num = 0.5*g\n",
    "    frac = a0 - (num/denom) * (amp)/np.pi\n",
    "    return frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinedamp(x,a,c,f,t):\n",
    "    fun = a*np.cos(2*np.pi*f*x)*np.exp(-1*(x/t)) + c\n",
    "    return fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stretchedexp(x,a,c,k,t):\n",
    "    fun = a*np.exp(-1*(x/t)**k) + c\n",
    "    return fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To fit the signal with a lorentzian function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitlorentzian(plotfun, expt='pulsedodmr', file=[], lb=None,ub=None):\n",
    "    \"Fitting parameters are ODMR frequency in GHz, Width in GHz, and Amplitude. \\\n",
    "    Attribute - expt - can either be 'odmr' or 'pulsedodmr'\"\n",
    "    if np.size(file) != 0:\n",
    "        Data = exc.load_by_id(file[0])\n",
    "    else:\n",
    "        lastExperiment = exc.load_last_experiment()\n",
    "        Data = lastExperiment.last_data_set()\n",
    "    xaxis = 'Frequency'\n",
    "    x1 = np.squeeze(Data.get_data(xaxis))\n",
    "    \n",
    "    if expt == 'odmr':\n",
    "        yaxis = 'Counts'\n",
    "        y1 = normalizeCounts(Data.get_data(yaxis),50)\n",
    "    elif expt == 'pulsedodmr':\n",
    "        y1 = np.squeeze(Data.get_data('Rebased_Counts'))  \n",
    "        \n",
    "    index = np.argmin(y1)\n",
    "    freq = x1[index]/1e9\n",
    "    \n",
    "    if (lb and ub) == None:\n",
    "        lb = [freq-0.01, 0.95, 0.007, 0.0005]\n",
    "        ub = [freq+0.01, 1.1, 0.02, 0.005]\n",
    "        \n",
    "    popt, pcov = curve_fit(lorentzian, x1/1e9, y1, bounds=(lb, ub))\n",
    "    fitname = 'Fit' + ', Resonance @ ' + str(round((popt[0]),3)) + ' GHz'\n",
    "    plotfun.add_scatter(x = x1 , y = lorentzian(x1/1e9,*popt), name = fitname) \n",
    "    return popt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To fit the signal with a damped sine function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitsinedamp(plotfun=None,file=[],expt='spinecho',lb=None,ub=None):   \n",
    "    \"Fitting parameters are Amplitude, Baseline Offset, Oscillation Frequency in GHz, and Decay Time in ns.\\\n",
    "    Attribute - expt - can either be 'rabi' or 'spinecho' or 'doubleecho'\"\n",
    "    if np.size(file) != 0:\n",
    "        Data = exc.load_by_id(file[0])\n",
    "    else:\n",
    "        lastExperiment = exc.load_last_experiment()\n",
    "        Data = lastExperiment.last_data_set()\n",
    "    xaxis = 'Time'\n",
    "    \n",
    "    \n",
    "    if expt == 'rabi':\n",
    "        x1 = np.squeeze(Data.get_data(xaxis))\n",
    "        y1 = np.squeeze(Data.get_data('Rebased_Counts'))\n",
    "    elif expt == 'spinecho':\n",
    "        x1 = 2*np.squeeze(Data.get_data(xaxis))\n",
    "        y1 = np.squeeze(Data.get_data('Rebased_Counts'))\n",
    "    elif expt == 'doubleecho':\n",
    "        x1 = 2*np.squeeze(Data.get_data(xaxis))\n",
    "        y1ms0 = np.squeeze(Data.get_data('Act_Counts'))\n",
    "        y1ms1 = np.squeeze(Data.get_data('Ref_Counts'))\n",
    "        y1 = y1ms0 - y1ms1\n",
    "        \n",
    "    ampMin = 0.8*(y1.max()-y1.min())/2\n",
    "    ampMax = 1.2*(y1.max()-y1.min())/2\n",
    "    boMin = 0.4*(y1.max()+y1.min())\n",
    "    boMax = 0.6*(y1.max()+y1.min())\n",
    "    freq = 1/(x1[y1.argmin()]*2)\n",
    "    freqMin = freq*0.7\n",
    "    freqMax = freq*1.3\n",
    "    if (lb and ub) == None:\n",
    "        lb = [ampMin, boMin, freqMin, 0]\n",
    "        ub = [ampMax, boMax, freqMax, 1e5]\n",
    "#     print(f'low bounds are: {lb}')\n",
    "#     print(f'upper bounds are: {ub}')\n",
    "    popt, pcov = curve_fit(sinedamp, x1, y1, bounds=(lb,ub))\n",
    "    yval = sinedamp(x1,*popt)\n",
    "    fitname = 'Fit' + ', \\u0394 = ' + str(round((popt[0]*2*100),1)) + ' %' + ', \\u03C0 = ' +  str(round((0.5/popt[2]),1)) + ' ns'\n",
    "    if plotfun is not None:\n",
    "        plotfun.add_scatter(x = x1 , y = yval, name = fitname,line=dict(shape='spline')) \n",
    "    return popt, pcov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To fit the signal with a stretched exponential function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_T2(plotfun,file=[],expt='doubleecho',threshold = 0.45, lb=[0,0,0,0],ub=[2,3,3,5e6], revivals=0):   \n",
    "    \"Fitting parameters are Amplitude, Baseline Offset, Power of Stretched Exponential, and Decay Time in ns.\\\n",
    "    Attribute - expt - can either be 'spinecho' or 'doubleecho'.\\\n",
    "    threshold is required for peak detection\"\n",
    "    \n",
    "    if np.size(file) != 0:\n",
    "        Data = exc.load_by_id(file[0])\n",
    "    else:\n",
    "        lastExperiment = exc.load_last_experiment()\n",
    "        Data = lastExperiment.last_data_set()\n",
    "        \n",
    "    x1 = 2*np.squeeze(Data.get_data('Time'))\n",
    "    if expt == 'spinecho':\n",
    "        y1 = np.squeeze(Data.get_data('Rebased_Counts'))  \n",
    "    elif expt == 'doubleecho':\n",
    "        y1ms0 = np.squeeze(Data.get_data('Act_Counts'))\n",
    "        y1ms1 = np.squeeze(Data.get_data('Ref_Counts'))\n",
    "        y1 = y1ms0 - y1ms1 \n",
    "        y1 = (y1 + max(y1))/(2*max(y1))\n",
    "    if revivals == 1:\n",
    "        peaks, _= find_peaks(y1,height=threshold,distance=6, width=3)\n",
    "        x0 = np.array([0])\n",
    "        y0 = np.array([y1[0]])\n",
    "        xpeaks = np.concatenate([x0, x1[peaks]], axis=0)\n",
    "        print(xpeaks)\n",
    "        ypeaks = np.concatenate([y0, y1[peaks]], axis=0)\n",
    "        print(ypeaks)\n",
    "    else:\n",
    "        xpeaks = x1\n",
    "        ypeaks = y1\n",
    "    \n",
    "    popt, pcov = curve_fit(stretchedexp, xpeaks, ypeaks, bounds=(lb,ub))\n",
    "    yval = stretchedexp(xpeaks,*popt)\n",
    "    \n",
    "    fitname = 'Fit, T2 = ' + str(round((popt[3]/1e3),1)) + ' \\u03BCs' \n",
    "    \n",
    "    #plotfun.add_scatter(x = xpeaks, y = ypeaks, mode='markers', name = 'Detected Peaks',marker=dict(color='red', size=10, opacity=0.5)) \n",
    "    plotfun.add_scatter(x = xpeaks , y = yval, name = fitname, line=dict(shape='spline'), mode='lines')\n",
    "    \n",
    "    return popt, pcov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To generate a  fourier transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fouriertransform(file=[],expt='spinecho'):\n",
    "    \"Attribute - expt - can either be 'rabi' or 'ramsey' or 'spinecho' or 'doubleecho'\"\n",
    "    layout = go.Layout(xaxis=dict(title='Frequency (GHz)'),yaxis=dict(title='Amplitude'),title = 'Fourier Transform of a ' + expt.capitalize() + ' signal')\n",
    "    freqPlot = go.Figure(layout=layout)\n",
    "    if np.size(file) != 0:\n",
    "        Data = exc.load_by_id(file[0])\n",
    "    else:\n",
    "        lastExperiment = exc.load_last_experiment()\n",
    "        Data = lastExperiment.last_data_set()\n",
    "        \n",
    "    xaxis = 'Time'\n",
    "    if expt == 'rabi' or expt == 'ramsey':\n",
    "        x1 = np.squeeze(Data.get_data(xaxis))\n",
    "        y1 = np.squeeze(Data.get_data('Rebased_Counts'))\n",
    "    elif expt == 'spinecho':\n",
    "        x1 = 2*np.squeeze(Data.get_data(xaxis))\n",
    "        y1 = np.squeeze(Data.get_data('Rebased_Counts'))\n",
    "    elif expt == 'doubleecho':\n",
    "        x1 = 2*np.squeeze(Data.get_data(xaxis))\n",
    "        y1ms0 = np.squeeze(Data.get_data('Act_Counts'))\n",
    "        y1ms1 = np.squeeze(Data.get_data('Ref_Counts'))\n",
    "        y1 = y1ms0 - y1ms1\n",
    "    elif expt == 'nmr':\n",
    "        x1 = np.squeeze(Data.get_data(xaxis))\n",
    "        y1ms0 = np.squeeze(Data.get_data('Act_Counts'))\n",
    "        y1ms1 = np.squeeze(Data.get_data('Ref_Counts'))\n",
    "        y1 = y1ms1 - y1ms0\n",
    "        \n",
    "    step = x1[1] - x1[0]\n",
    "        \n",
    "    fourTrans = np.fft.fft(y1)\n",
    "    freqs = np.fft.fftfreq(y1.shape[-1], step)\n",
    "    fourTransReal = fourTrans.real\n",
    "    freqPlot.add_scatter(x = freqs, y = fourTransReal,line=dict(shape='spline'), mode='lines')\n",
    "    return freqPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To calculate and plot magnitude + direction of the applied field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magfield(odmr1=[2.87],odmr2=[2.87],strain=5):\n",
    "    \"Input ODMR frequencies in GHz and strain splitting in MHz\"\n",
    "    \n",
    "    g = 2.8024e6\n",
    "    D = 2.877e9\n",
    "    \n",
    "    pts = np.size(odmr1)\n",
    "    theta = np.zeros([pts])\n",
    "    B0 = np.zeros([pts])\n",
    "    \n",
    "    for i in range (pts):\n",
    "        n1 = odmr1[i]*1e9 + strain*1e6/2\n",
    "        n2 = odmr2[i]*1e9 - strain*1e6/2\n",
    "        P = n1**2 + n2**2 - n1*n2\n",
    "        Q = (n1 + n2)*(2*n1**2 + 2*n2**2-5*n1*n2)\n",
    "        B = np.sqrt((P-D**2)/3);\n",
    "        c2t = (Q + 9*D*B**2+2*D**3)/(27*D*B**2);\n",
    "        angle = np.arccos(np.sqrt(c2t))*180/np.pi;\n",
    "        theta[i] = round(angle,2);\n",
    "        B = B.real/g;\n",
    "        B0[i] = round(B,2);\n",
    "    \n",
    "    fig = tools.make_subplots(rows=1, cols=2)\n",
    "    plotfun = go.Figure(fig)\n",
    "    plotfun.layout.yaxis.title = 'Magnetic Field Magnitude (gauss)'\n",
    "    plotfun.layout.yaxis2.title = 'Angle to NV axis (degrees)'\n",
    "    plotfun.add_bar(y=B0,row=1,col=1,name='Magnitude')\n",
    "    plotfun.add_bar(y=theta,row=1,col=2,name='Angle')\n",
    "    plotfun.layout.title = 'Checking magnetic field alignment'\n",
    "    return plotfun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To plot recent and saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotdata(expt='rabi', plotcurrent=1, normalize= 1, files=[300], nPi = []): \n",
    "    \"Attribute - expt - can either be 'counting' or 'odmr' or 'pulsedodmr' or 'rabi' or 'ramsey' or 'spinecho' or 'doubleecho' or 'nmr'.\\\n",
    "    If value of plotcurrent is 1 then it will plot the current data. If value of normalize is 1 then it will normalize 'odmr' and 'doubleecho' signal.\"\n",
    "    if plotcurrent == 1:        \n",
    "        filesize = np.size(files) + 1\n",
    "    else:\n",
    "        filesize = np.size(files)  \n",
    "        \n",
    "    plotfun = go.Figure()    \n",
    "    for i in range(filesize):\n",
    "        if plotcurrent == 1 and i == filesize-1:\n",
    "            Data2 = exc.load_last_experiment()\n",
    "            Data2 = Data2.last_data_set()\n",
    "        else:    \n",
    "            Data2 = exc.load_by_id(files[i])\n",
    "        if expt == 'spinecho':\n",
    "            x2 = 2*np.squeeze(Data2.get_data('Time'))\n",
    "            y2 = np.squeeze(Data2.get_data('Rebased_Counts'))\n",
    "            plotfun.layout = go.Layout(xaxis=dict(title='Time (ns)'),yaxis=dict(title='Counts'),title=expt.capitalize())                  \n",
    "        elif expt == 'doubleecho':\n",
    "            if nPi == [] or nPi[i] == 1:\n",
    "                x2 = 2*np.squeeze(Data2.get_data('Time'))\n",
    "            else:\n",
    "                x2 = nPi[i]*np.squeeze(Data2.get_data('Time'))\n",
    "            y2ms0 = np.squeeze(Data2.get_data('Act_Counts'))\n",
    "            y2ms1 = np.squeeze(Data2.get_data('Ref_Counts'))\n",
    "            y2 = y2ms0 - y2ms1   \n",
    "            plotfun.layout = go.Layout(xaxis=dict(title='Time (ns)'),yaxis=dict(title='Counts'),title='Spinecho Double Measure')\n",
    "            if normalize == 1:\n",
    "                y2 = (y2 + max(y2))/(2*max(y2))\n",
    "        elif expt == 'nmr':\n",
    "            x2 = np.squeeze(Data2.get_data('Time'))\n",
    "            y2ms0 = np.squeeze(Data2.get_data('Act_Counts'))\n",
    "            y2ms1 = np.squeeze(Data2.get_data('Ref_Counts'))\n",
    "            y2 = y2ms0 - y2ms1   \n",
    "            plotfun.layout = go.Layout(xaxis=dict(title='Time (ns)'),yaxis=dict(title='Counts'),title='NMR')\n",
    "            if normalize == 1:\n",
    "                y2 = (y2 + max(y2))/(2*max(y2))\n",
    "        elif expt == 'odmr':\n",
    "            x2 = np.squeeze(Data2.get_data('Frequency'))\n",
    "            y2 = np.squeeze(Data2.get_data('Counts'))\n",
    "            plotfun.layout = go.Layout(xaxis=dict(title='Frequency (Hz)'),yaxis=dict(title='Counts'),title=expt.upper())\n",
    "            if normalize == 1:\n",
    "                y2 = normalizeCounts(Data2.get_data('Counts'),50)\n",
    "                layout = go.Layout(xaxis=dict(title='Frequency (Hz)'),yaxis=dict(title='Normalized Counts'),title=expt.upper())\n",
    "        elif expt == 'pulsedodmr':\n",
    "            x2 = np.squeeze(Data2.get_data('Frequency'))\n",
    "            y2 = np.squeeze(Data2.get_data('Rebased_Counts'))   \n",
    "            plotfun.layout = go.Layout(xaxis=dict(title='Frequency (Hz)'),yaxis=dict(title='Counts'),title='Pulsed ODMR')\n",
    "        elif expt == 'g2':\n",
    "            x2 = np.squeeze(Data2.get_data('Time'))\n",
    "            y2 = np.squeeze(Data2.get_data('Norm_Counts'))\n",
    "            plotfun.layout = go.Layout(xaxis=dict(title='Time dif'), yaxis=dict(title='Normalised Counts'), title='g2 Dip')\n",
    "        else:\n",
    "            x2 = np.squeeze(Data2.get_data('Time'))\n",
    "            y2 = np.squeeze(Data2.get_data('Rebased_Counts'))     \n",
    "            plotfun.layout = go.Layout(xaxis=dict(title='Time (ns)'),yaxis=dict(title='Counts'),title=expt.capitalize())\n",
    "        if plotcurrent == 1 and i == filesize-1:\n",
    "            plotfun.add_scatter(x = x2, y = y2, name = 'Recent Data', mode='lines+markers') \n",
    "        else:       \n",
    "            plotfun.add_scatter(x = x2, y = y2, name = files[i], mode='lines+markers') \n",
    "    return plotfun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To update recent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updatedata(plotfun, expt='rabi', sleeptime=2, normalize=1, animation=1):\n",
    "    \"Attribute - expt - can either be 'counting' or 'odmr' or 'pulsedodmr' or rabi' or 'ramsey' or 'spinecho' or 'doubleecho'.\\\n",
    "    If value of plotcurrent is 1 then it will plot the current data. If value of normalize is 1 then it will normalize 'odmr' and 'doubleecho' signal.\"\n",
    "    for i in range(10000):\n",
    "        sleep(sleeptime)\n",
    "        if animation == 1:\n",
    "            with plotfun.batch_animate(easing = 'quad'):   \n",
    "                Data2 = exc.load_last_experiment()\n",
    "                Data2 = Data2.last_data_set()\n",
    "                if expt == 'doubleecho':\n",
    "                    y2ms0 = np.squeeze(Data2.get_data('Act_Counts'))\n",
    "                    y2ms1 = np.squeeze(Data2.get_data('Ref_Counts'))\n",
    "                    y2 = y2ms0 - y2ms1  \n",
    "                    if normalize == 1:\n",
    "                        y2 = (y2 + max(y2))/(2*max(y2))\n",
    "                elif expt == 'nmr':\n",
    "                    y2ms0 = np.squeeze(Data2.get_data('Act_Counts'))\n",
    "                    y2ms1 = np.squeeze(Data2.get_data('Ref_Counts'))\n",
    "                    y2 = y2ms0 - y2ms1  \n",
    "                    if normalize == 1:\n",
    "                        y2 = (y2 + max(y2))/(2*max(y2))\n",
    "                elif expt == 'odmr':\n",
    "                    y2 = np.squeeze(Data2.get_data('Counts'))\n",
    "                    if normalize == 1:\n",
    "                        y2 = normalizeCounts(Data2.get_data('Counts'),50)\n",
    "                elif expt == 'g2':\n",
    "                    y2 = np.squeeze(Data2.get_data('Norm_Counts'))\n",
    "                else:\n",
    "                    y2 = np.squeeze(Data2.get_data('Rebased_Counts'))     \n",
    "                plotfun.data[-1].y = y2\n",
    "        else:\n",
    "            Data2 = exc.load_last_experiment()\n",
    "            Data2 = Data2.last_data_set()\n",
    "            if expt == 'doubleecho':\n",
    "                y2ms0 = np.squeeze(Data2.get_data('Act_Counts'))\n",
    "                y2ms1 = np.squeeze(Data2.get_data('Ref_Counts'))\n",
    "                y2 = y2ms0 - y2ms1  \n",
    "                if normalize == 1:\n",
    "                    y2 = (y2 + max(y2))/(2*max(y2))\n",
    "            elif expt == 'nmr':\n",
    "                y2ms0 = np.squeeze(Data2.get_data('Act_Counts'))\n",
    "                y2ms1 = np.squeeze(Data2.get_data('Ref_Counts'))\n",
    "                y2 = y2ms0 - y2ms1  \n",
    "                if normalize == 1:\n",
    "                    y2 = (y2 + max(y2))/(2*max(y2))\n",
    "            elif expt == 'odmr':\n",
    "                y2 = np.squeeze(Data2.get_data('Counts'))\n",
    "                if normalize == 1:\n",
    "                    y2 = normalizeCounts(Data2.get_data('Counts'),50)\n",
    "            elif expt == 'g2':\n",
    "                y2 = np.squeeze(Data2.get_data('Counts'))\n",
    "            else:\n",
    "                y2 = np.squeeze(Data2.get_data('Rebased_Counts'))     \n",
    "            plotfun.data[-1].y = y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
